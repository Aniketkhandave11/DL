{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sb2fFFaZlSL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Step 1: Prepare the dataset (Assume a folder structure with subfolders for each class)\n",
        "def load_images_from_folder(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_names = os.listdir(data_directory)  # Class names (subfolders)\n",
        "\n",
        "    for label_name in label_names:\n",
        "        label_dir = os.path.join(data_directory, label_name)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, img_name)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, (64, 64))  # Resize image to 64x64\n",
        "                    images.append(img)\n",
        "                    labels.append(label_name)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Step 2: Load images and labels\n",
        "data_directory = '/path/to/your/data'  # Set the path to your dataset\n",
        "images, labels = load_images_from_folder(data_directory)\n",
        "\n",
        "# Step 3: Encode labels (Convert class labels to integers)\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Step 4: Normalize the images (Scale the pixel values to [0, 1])\n",
        "images = images / 255.0\n",
        "\n",
        "# Step 5: One-hot encode the labels for multiclass classification\n",
        "encoded_labels = to_categorical(encoded_labels)\n",
        "\n",
        "# Step 6: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 7: Data Augmentation (optional, to improve model performance)\n",
        "train_datagen = ImageDataGenerator(rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "# Step 8: Build CNN model for multiclass classification\n",
        "model = Sequential()\n",
        "\n",
        "# First convolutional layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Second convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the 2D matrix to 1D vector\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer (softmax for multiclass classification)\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Step 9: Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 10: Train the model\n",
        "model.fit(train_datagen.flow(X_train, y_train, batch_size=32), epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 11: Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Step 12: Make predictions on new images\n",
        "test_image_path = '/path/to/test_image.jpg'  # Path to a test image\n",
        "test_image = cv2.imread(test_image_path)\n",
        "test_image = cv2.resize(test_image, (64, 64))\n",
        "test_image = test_image / 255.0  # Normalize\n",
        "test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Predict the class of the test image\n",
        "predicted_class = model.predict(test_image)\n",
        "predicted_class_label = label_encoder.inverse_transform([np.argmax(predicted_class)])\n",
        "print(f\"Predicted class: {predicted_class_label[0]}\")\n"
      ]
    }
  ]
}